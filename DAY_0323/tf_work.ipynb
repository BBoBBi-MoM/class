{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19998 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\Administrator\\Desktop\\Dataset\\PetImages\\train',\n",
    "                                                 target_size = (224,224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\Administrator\\Desktop\\Dataset\\PetImages\\test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer1 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=64,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.sub_sampling_layer1 = layers.MaxPooling2D(kernel_size=\"same\",strides=2)\n",
    "        \n",
    "        self.conv_layer2 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=128,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.sub_sampling_layer2 = layers.MaxPooling2D(kernel_size=\"same\",strides=2)\n",
    "        \n",
    "\n",
    "        self.conv_layer3 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=256,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.conv_layer4 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=256,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.sub_sampling_layer3 = layers.MaxPooling2D(kernel_size=\"same\",strides=2)\n",
    "\n",
    "\n",
    "        self.conv_layer5 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=512,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.conv_layer6 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=512,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.sub_sampling_layer4 = layers.MaxPooling2D(kernel_size=\"same\",strides=2)\n",
    "\n",
    "        self.conv_layer7 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=512,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.conv_layer8 = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=512,kernel_size=3,strides=1,padding=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.sub_sampling_layer5 = layers.MaxPooling2D(kernel_size=\"same\",strides=2)\n",
    "        \n",
    "        self.flatten = layers.Flatten() \n",
    "\n",
    "        self.fc_layer1 = tf.keras.Sequential([\n",
    "        layers.Dense(4096),\n",
    "        layers.ReLU(),\n",
    "        layers.Dropout(0.5)\n",
    "        ])\n",
    "        self.fc_layer2 = tf.keras.Sequential([\n",
    "        layers.Dense(4096),\n",
    "        layers.ReLU(),\n",
    "        layers.Dropout(0.5)\n",
    "        ])\n",
    "        self.output_layer = tf.keras.Sequential([\n",
    "        layers.Dense(2),\n",
    "        layers.Activation('sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.sub_sampling_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.sub_sampling_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.conv_layer4(x)\n",
    "        x = self.sub_sampling_layer3(x)\n",
    "        x = self.conv_layer5(x)\n",
    "        x = self.conv_layer6(x)\n",
    "        x = self.sub_sampling_layer4(x)\n",
    "        x = self.conv_layer7(x)\n",
    "        x = self.conv_layer8(x)\n",
    "        x = self.sub_sampling_layer5(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layer1(x)\n",
    "        x = self.fc_layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m VGG11()\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mVGG11.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m----> 6\u001b[0m         layers\u001b[39m.\u001b[39;49mConv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,strides\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,padding\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m      7\u001b[0m         layers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[0;32m      8\u001b[0m         layers\u001b[39m.\u001b[39mReLU()\n\u001b[0;32m      9\u001b[0m     ])\n\u001b[0;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msub_sampling_layer1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mMaxPooling2D(kernel_size\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m,strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m     13\u001b[0m         layers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     14\u001b[0m         layers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[0;32m     15\u001b[0m         layers\u001b[39m.\u001b[39mReLU()\n\u001b[0;32m     16\u001b[0m     ])\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\dtensor\\utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[1;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d.py:179\u001b[0m, in \u001b[0;36mConv2D.__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39m@utils\u001b[39m\u001b[39m.\u001b[39mallow_initializer_layout\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    178\u001b[0m ):\n\u001b[1;32m--> 179\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    180\u001b[0m         rank\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    181\u001b[0m         filters\u001b[39m=\u001b[39mfilters,\n\u001b[0;32m    182\u001b[0m         kernel_size\u001b[39m=\u001b[39mkernel_size,\n\u001b[0;32m    183\u001b[0m         strides\u001b[39m=\u001b[39mstrides,\n\u001b[0;32m    184\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m    185\u001b[0m         data_format\u001b[39m=\u001b[39mdata_format,\n\u001b[0;32m    186\u001b[0m         dilation_rate\u001b[39m=\u001b[39mdilation_rate,\n\u001b[0;32m    187\u001b[0m         groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    188\u001b[0m         activation\u001b[39m=\u001b[39mactivations\u001b[39m.\u001b[39mget(activation),\n\u001b[0;32m    189\u001b[0m         use_bias\u001b[39m=\u001b[39muse_bias,\n\u001b[0;32m    190\u001b[0m         kernel_initializer\u001b[39m=\u001b[39minitializers\u001b[39m.\u001b[39mget(kernel_initializer),\n\u001b[0;32m    191\u001b[0m         bias_initializer\u001b[39m=\u001b[39minitializers\u001b[39m.\u001b[39mget(bias_initializer),\n\u001b[0;32m    192\u001b[0m         kernel_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(kernel_regularizer),\n\u001b[0;32m    193\u001b[0m         bias_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(bias_regularizer),\n\u001b[0;32m    194\u001b[0m         activity_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(activity_regularizer),\n\u001b[0;32m    195\u001b[0m         kernel_constraint\u001b[39m=\u001b[39mconstraints\u001b[39m.\u001b[39mget(kernel_constraint),\n\u001b[0;32m    196\u001b[0m         bias_constraint\u001b[39m=\u001b[39mconstraints\u001b[39m.\u001b[39mget(bias_constraint),\n\u001b[0;32m    197\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:142\u001b[0m, in \u001b[0;36mConv.__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    137\u001b[0m     kernel_size, rank, \u001b[39m\"\u001b[39m\u001b[39mkernel_size\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m )\n\u001b[0;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrides \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    140\u001b[0m     strides, rank, \u001b[39m\"\u001b[39m\u001b[39mstrides\u001b[39m\u001b[39m\"\u001b[39m, allow_zero\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39;49mnormalize_padding(padding)\n\u001b[0;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39mnormalize_data_format(data_format)\n\u001b[0;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation_rate \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    145\u001b[0m     dilation_rate, rank, \u001b[39m\"\u001b[39m\u001b[39mdilation_rate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\conv_utils.py:235\u001b[0m, in \u001b[0;36mnormalize_padding\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 235\u001b[0m padding \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m padding \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcausal\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `padding` argument must be a list/tuple or one of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcausal\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, only for `Conv1D). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    240\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: \u001b[39m\u001b[39m{\u001b[39;00mpadding\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "model = VGG11()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
